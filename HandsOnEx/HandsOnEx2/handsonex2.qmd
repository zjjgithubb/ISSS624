---
title: "Hands-On Ex 2"

date: "23 Nov 23"
date-modified: "last-modified" 

format: html
execute: 
  echo: true
  eval: true
  warning: false
  
editor: visual 
---

# Overview 

In this hands-on exercise, we will learn how to compute spatial weights using R. By the end to this hands-on exercise, we will be able to:

-   import geospatial data using appropriate function(s) of **sf** package,

-   import csv file using appropriate function of **readr** package,

-   perform relational join using appropriate join function of **dplyr** package,

-   compute spatial weights using appropriate functions of **spdep** package, and

-   calculate spatially lagged variables using appropriate functions of **spdep** package.

## The Study Area and Data 

We will be using the following data sets:

-   Geospatial Data: Hunan County Boundary Layer

-   Aspatial Data: Hunan's local development indicators in 2012. Hunan_2012.csv

## Loading the Packages 

We will be using the following packages for this exercise:

New package for this exercise - **spdep**

The **spdep package** is a collection of functions for spatial data analysis in R. It provides tools for creating spatial weights matrices, performing spatial autocorrelation tests, and fitting spatial regression models. The package is widely used in a variety of fields, including geography, economics, and ecology.

```{r}

pacman::p_load(sf, spdep, tmap, tidyverse, knitr)
```

# Getting the data ready

First - we will import the data.

We will start with the geospatial data - Hunan county, which is in ESRI shapefile format.

```{r}

hunan <- st_read(dsn = "data/geospatial", 
                 layer = "Hunan")
```

Next, we will import the aspatial data using the readr package.

```{r}

hunan2012 <- read_csv("data/aspatial/Hunan_2012.csv")
```

Quick check on the data to learn more about the data. It lists the County name and the various indicators.

```{r}

head(hunan2012)
```

## Performing relational join 

We will update the attribute table update the attribute table of *hunan*\'s SpatialPolygonsDataFrame with the attribute fields of *hunan2012* dataframe. This is performed by using *left_join()* of **dplyr** package.

```{r}

hunan <- left_join(hunan,hunan2012)%>%
  select(1:4, 7, 15)
```

1.  **`left_join(hunan, hunan2012)`**: This line performs a left join between the data frames **`hunan`** and **`hunan2012`**. The left join includes all rows from the **`hunan`** data frame and the matching rows from the **`hunan2012`** data frame based on a common key or keys. The result is a data frame with columns from both data frames.

2.  **`%>%`**: The pipe operator (**`%>%`**) is used to pass the result of the left join to the next operation.

3.  **`select(1:4, 7, 15)`**: This line selects specific columns from the joined data frame. Columns 1 through 4, column 7, and column 15 are retained in the final data frame, and the rest are dropped.

## Visualising the Data - Regional Development Indicator 

We will prepare a base map and a choropleth map showing the distribution of GDPPC 2012 by using *qtm()* of **tmap** package.

```{r}

basemap <- tm_shape(hunan) +
  tm_polygons() +
  tm_text("NAME_3", size=0.5)

gdppc <- qtm(hunan, "GDPPC")
tmap_arrange(basemap, gdppc, asp=1, ncol=2)
```

# Computing Contiguity Spatial Weights

## Overview of Contiguity Spatial Weights

In spatial analysis, contiguity spatial weights represent the connections or relationships between spatial units, such as regions, countries, or points on a map. These weights are typically constructed based on the geometric proximity of the units, indicating whether they share a common border or are within a certain distance of each other. The specific type of contiguity used depends on the research question and the nature of the data.

**Types of Contiguity Spatial Weights**

There are two main types of contiguity spatial weights:

1.   **Rook contiguity:** Units are considered neighbors if they share a common edge.

2.  **Queen contiguity:** Units are considered neighbors if they share a common edge or vertex.

These two types of contiguity differ in how they define connectivity. Rook contiguity is more restrictive, while queen contiguity is more inclusive. The choice of contiguity weight depends on the specific application and the research question.

**Applications of Contiguity Spatial Weights**

Contiguity spatial weights are used in various spatial analysis applications, including:

1.   **Spatial autocorrelation analysis:** Identifying patterns of similarity or dissimilarity in spatial data.

2.  **Spatial regression modeling:** Accounting for spatial dependence in statistical models.

3.  **Spatial interpolation:** Estimating values at unsampled locations based on surrounding values.

4.  **Spatial diffusion modeling:** Analyzing the spread of phenomena over space and time.

**Construction of Contiguity Spatial Weights**

Contiguity spatial weights are typically constructed using spatial data structures and algorithms. These tools allow for efficient and accurate identification of neighbors based on geometric proximity. The specific construction method depends on the type of spatial data (polygons, points, lines) and the type of contiguity (rook or queen).

**Normalization of Contiguity Spatial Weights**

Contiguity spatial weights are often normalized to ensure that they are comparable across different spatial units and studies. Normalization methods can involve row-standardization, column-standardization, or other techniques.

**Importance of Contiguity Spatial Weights**

Contiguity spatial weights play a crucial role in spatial analysis by providing a formal representation of spatial relationships between units. They allow researchers to incorporate spatial dependence into statistical models and analyze the impact of spatial context on various phenomena.

## Compute QUEEN contiguity based neighbours

Computing the Queen contiguity weight matrix.

```{r}

wm_q <- poly2nb(hunan, queen=TRUE)
summary(wm_q)
```

The summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one heighbours.

For each polygon in our polygon object, *wm_q* lists all neighboring polygons. For example, to see the neighbors for the first polygon in the object, type:

```{r}

wm_q[[1]]
```

Polygon 1 has 5 neighbors. The numbers represent the polygon IDs as stored in hunan SpatialPolygonsDataFrame class.

We can retrive the county name of Polygon ID=1 by using the code chunk below:

```{r}

hunan$County[1]
```

The output reveals that Polygon ID=1 is Anxiang county.

To reveal the county names of the five neighboring polygons, the code chunk will be used:

```{r}

hunan$NAME_3[c(2,3,4,57,85)]
```

We can retrieve the GDPPC of these five countries by using the code chunk below.

```{r}

nb1 <- wm_q[[1]]
nb1 <- hunan$GDPPC[nb1]
nb1
```

The printed output above shows that the GDPPC of the five nearest neighbours based on Queen\'s method are 20981, 34592, 24473, 21311 and 22879 respectively.

We can display the complete weight matrix by using *str()*.

```{r}
str(wm_q)
```

## Computing ROOK contiguity based neighbours

The code chunk below is used to compute Rook contiguity weight matrix.

```{r}
wm_r <- poly2nb(hunan, queen=FALSE)
summary(wm_r)
```

The summary report above shows that there are 88 area units in Hunan. The most connect area unit has 10 neighbours. There are two area units with only one neighbours.

## Visualising contiguity weights 

A connectivity graph takes a point and displays a line to each neighboring point. We are working with polygons at the moment, so we will need to get points in order to make our connectivity graphs. The most typically method for this will be polygon centroids. We will calculate these in the sf package before moving onto the graphs. Getting Latitude and Longitude of Polygon Centroids

We will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid. We will be using map_dbl variation of map from the purrr package. For more documentation, check out map documentation

To get our longitude values we map the st_centroid function over the geometry column of us.bound and access the longitude value through double bracket notation \[\[\]\] and 1. This allows us to get only the longitude, which is the first value in each centroid.

```{r}
longitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])
```

We do the same for latitude with one key difference. We access the second value per each centroid with \[\[2\]\].

```{r}
latitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])
```

Now that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.

```{r}
coords <- cbind(longitude, latitude)
```

We check to see if things are formatted correctly.

```{r}
head(coords)
```

### Plotting QUEEN map 

```{r}
plot(hunan$geometry, border="lightgrey")
plot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= "red")
```

### Plotting ROOK map

```{r}
plot(hunan$geometry, border="lightgrey")
plot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = "red")
```

### Plotting both QUEEN and ROOK maps

```{r}
par(mfrow=c(1,2))
plot(hunan$geometry, border="lightgrey", main="Queen Contiguity")
plot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= "red")
plot(hunan$geometry, border="lightgrey", main="Rook Contiguity")
plot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = "red")
```

## Computing distance based neighbours 

In this section, you will learn how to derive distance-based weight matrices by using [*dnearneigh()*](https://r-spatial.github.io/spdep/reference/dnearneigh.html) of **spdep** package.

The function identifies neighbours of region points by Euclidean distance with a distance band with lower d1= and upper d2= bounds controlled by the bounds= argument. If unprojected coordinates are used and either specified in the coordinates object x or with x as a two column matrix and longlat=TRUE, great circle distances in **km** will be calculated assuming the WGS84 reference ellipsoid.

### Determine the cut-off distance 

Firstly, we need to determine the upper limit for distance band by using the steps below:

-   Return a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using [*knearneigh()*](https://r-spatial.github.io/spdep/reference/knearneigh.html) of **spdep**.

-   Convert the knn object returned by *knearneigh()* into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using [*knn2nb()*](https://r-spatial.github.io/spdep/reference/knn2nb.html).

-   Return the length of neighbour relationship edges by using [*nbdists()*](https://r-spatial.github.io/spdep/reference/nbdists.html) of **spdep**. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.

-   Remove the list structure of the returned object by using [**unlist()**](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/unlist).

```{r}
#coords <- coordinates(hunan)
k1 <- knn2nb(knearneigh(coords))
k1dists <- unlist(nbdists(k1, coords, longlat = TRUE))
summary(k1dists)
```

The summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.

### Computing fixed distance weight matrix

Now, we will compute the distance weight matrix by using *dnearneigh()* as shown in the code chunk below.

dnearneigh(your_spatial_data, d1 = distance_threshold, longlat = FALSE) - **`dnearneigh`**: This function from the **`spdep`** package creates a neighbors list based on a specified distance threshold (**`d1`**). The **`longlat`** parameter is set to **`FALSE`** because it assumes the data is in planar coordinates. But we are using longlat so it is set to TRUE.

```{r}
wm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)
wm_d62
```

-   **Number of regions:** There are 88 regions in your spatial data.

-   **Number of nonzero links:** The total number of links or connections between regions is 324.

-   **Percentage nonzero weights:** This is the percentage of nonzero weights in the spatial weights matrix. In your case, it's 4.183884%, indicating that a small percentage of all possible pairwise connections have been defined as neighbors.

-   **Average number of links:** On average, each region has approximately 3.68 links or neighbors.

Next, we will use *str()* to display the content of wm_d62 weight matrix.

```{r}
str(wm_d62)
```

Another way to display the structure of the weight matrix is to combine [*table()*](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/table) and [*card()*](https://r-spatial.github.io/spdep/reference/card.html) of spdep.

```{r}
table(hunan$County, card(wm_d62))
```

```{r}
n_comp <- n.comp.nb(wm_d62)
n_comp$nc
```

```{r}
table(n_comp$comp.id)
```

### Plotting fixed distance weight matrix

Next - we will plot the data onto the map.

```{r}
plot(hunan$geometry, border="lightgrey")
plot(wm_d62, coords, add=TRUE)
plot(k1, coords, add=TRUE, col="red", length=0.08)
```

The red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.

Alternatively, we can plot both of them next to each other by using the code chunk below.

```{r}
par(mfrow=c(1,2))
plot(hunan$geometry, border="lightgrey", main="1st nearest neighbours")
plot(k1, coords, add=TRUE, col="red", length=0.08)
plot(hunan$geometry, border="lightgrey", main="Distance link")
plot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)
```

## Computing adaptive distance weight matrix

One of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.

It is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.

-   **`knn2nb`**: This function converts a k-nearest neighbors list to a neighbor list object. It takes the output of the **`knearneigh`** function (which calculates k-nearest neighbors) and converts it to a neighbor list suitable for spatial analysis.

-   **`knearneigh(coords, k=6)`**: This function calculates the k-nearest neighbors for a given set of coordinates (**`coords`**) with a specified value of **`k`** (in this case, **`k = 6`**).

```{r}
knn6 <- knn2nb(knearneigh(coords, k=6))
knn6
```

Similarly, we can display the content of the matrix by using *str()*.

```{r}
str(knn6)
```

### Plotting distance based neighbours 

```{r}
plot(hunan$geometry, border="lightgrey")
plot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = "red")
```

## Weights based on Inverse Distance Weighting

The IDW method estimates values for unmeasured locations based on the values observed at nearby locations. The basic idea is that values at a particular location are influenced more by values at nearby locations than by those farther away.

Here's a brief explanation of how IDW works:

1.  **Inverse Distance Weighting:**

    -   IDW assigns weights to measured values at known locations based on their distance to the location where you want to estimate a value.

    -   The weights are typically inversely proportional to the distance from the known points. Closer points have higher weights, indicating a stronger influence on the estimated value.

2.  **Weighted Average:**

    -   The estimated value at a specific location is calculated as a weighted average of the observed values at nearby locations, with weights determined by their inverse distances.

3.  **Power Parameter:**

    -   IDW often includes a power parameter (p) that allows you to control the rate at which the weights decrease with distance. A higher value of p means that closer points have even more influence on the estimated value.

First, we will compute the distances between areas by using [*nbdists()*](https://r-spatial.github.io/spdep/reference/nbdists.html) of **spdep**.

```{r}
dist <- nbdists(wm_q, coords, longlat = TRUE)
ids <- lapply(dist, function(x) 1/(x))
ids
```

### Row-standardised weights matrix

Next, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=\"W\"). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors\' values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we\'ll stick with the style=\"W\" option for simplicity\'s sake but note that other more robust options are available, notably style=\"B\".

```{r}
rswm_q <- nb2listw(wm_q, style="W", zero.policy = TRUE)
rswm_q
```

The zero.policy=TRUE option allows for lists of non-neighbors. This should be used with caution since the user may not be aware of missing neighbors in their dataset however, a zero.policy of FALSE would return an error.

To see the weight of the first polygon\'s eight neighbors type:

```{r}
rswm_q$weights[10]
```

Each neighbor is assigned a 0.125 of the total weight. This means that when R computes the average neighboring income values, each neighbor\'s income will be multiplied by 0.2 before being tallied.

Using the same method, we can also derive a row standardised distance weight matrix by using the code chunk below.

```{r}
rswm_ids <- nb2listw(wm_q, glist=ids, style="B", zero.policy=TRUE)
rswm_ids
```

```{r}
rswm_ids$weights[1]
```

```{r}
summary(unlist(rswm_ids$weights))
```

## Application of Spatial Weight Matrix 

1.  **Spatial Lag with Row-Standardized Weights:**

    -   This involves creating a new variable for each observation that represents the average or weighted average of the variable of interest in its neighboring locations.

    -   The weights used for the spatial lag are row-standardized weights, meaning that each row of the spatial weights matrix sums to 1.

2.  **Spatial Lag as a Sum of Neighboring Values:**

    -   Instead of using row-standardized weights, this approach calculates the spatial lag as the sum of the values of the variable of interest in neighboring locations.

    -   This is a simple summation of the neighboring values without normalization.

3.  **Spatial Window Average:**

    -   This involves creating a new variable for each observation that represents the average value of the variable of interest within a specified spatial window or neighborhood around that observation.

    -   The window can be defined by distance, number of neighbors, or some other criterion.

4.  **Spatial Window Sum:**

    -   Similar to the spatial window average, this creates a new variable that represents the sum of the variable of interest within a specified spatial window or neighborhood around each observation.

The choice of which spatial lag variable to use depends on the specific research question, the characteristics of your data, and the underlying assumptions of your analysis. Here's a general guide on when to use each of the four spatial lag variables you mentioned:

1.  **Spatial Lag with Row-Standardized Weights:**
    -   **Use Case:** This is a commonly used spatial lag variable when you want to account for spatial autocorrelation and consider the average or weighted average of a variable in neighboring locations.
    -   **Considerations:** Useful when you want each observation's influence to be normalized by its connectivity to neighbors. It is often used in spatial econometrics.
2.  **Spatial Lag as a Sum of Neighboring Values:**
    -   **Use Case:** When you are interested in capturing the cumulative impact of neighboring values on a variable, without normalizing by the number of neighbors.
    -   **Considerations:** May be appropriate when you want to emphasize the total influence of neighbors, regardless of the number of neighbors.
3.  **Spatial Window Average:**
    -   **Use Case:** Useful when you want to smooth the variable by considering the average value within a specified spatial window or neighborhood around each observation.
    -   **Considerations:** Good for capturing a local spatial pattern while reducing noise. The size of the window affects the level of smoothing.
4.  **Spatial Window Sum:**
    -   **Use Case:** When you want to emphasize the cumulative impact of the variable within a specified spatial window or neighborhood.
    -   **Considerations:** Similar to the spatial window average, but places more weight on higher values within the window. Useful when you want to capture intensity or density rather than an average.

Consider the following factors when choosing which spatial lag variable to use:

-   **Spatial Patterns:** Consider the spatial patterns in your data. Are you interested in capturing local averages, totals, or smoothing effects?

-   **Assumptions:** Think about the assumptions underlying each approach. For example, row-standardized weights normalize the influence of neighbors, while a simple sum does not.

-   **Interpretability:** Choose the variable that aligns with the interpretability of your research question. What type of spatial influence are you trying to capture?

-   **Modeling Goals:** If you're incorporating these spatial lag variables into a regression model, consider the assumptions and requirements of the modeling technique you are using.

Experimenting with different spatial lag variables and assessing their impact on your analysis can also provide insights into which approach is most appropriate for your specific context.

### Spatial lag with row-standardised weights

Finally, we\'ll compute the average neighbor GDPPC value for each polygon. These values are often referred to as **spatially lagged values**.

```{r}
GDPPC.lag <- lag.listw(rswm_q, hunan$GDPPC)
GDPPC.lag
```

We utilised the rswm_q here.

Recalled in the previous section, we retrieved the GDPPC of these five countries by using the code chunk below.

```{r}
nb1 <- wm_q[[1]]
nb1 <- hunan$GDPPC[nb1]
nb1
```

Question: Can you see the meaning of Spatial lag with row-standardized weights now? - We are summarising the values of hte variable in the neighbouring locations in a way that fives equal importance to each neighbour and ensured that the influence of neghbours is normalised.

We can append the spatially lag GDPPC values onto hunan sf data frame by using the code chunk below.

```{r}
lag.list <- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))
lag.res <- as.data.frame(lag.list)
colnames(lag.res) <- c("NAME_3", "lag GDPPC")
hunan <- left_join(hunan,lag.res)
```

The following table shows the average neighboring income values (stored in the Inc.lag object) for each county.

```{r}
head(hunan)
```

Next, we will plot both the GDPPC and spatial lag GDPPC for comparison using the code chunk below.

```{r}
gdppc <- qtm(hunan, "GDPPC")
lag_gdppc <- qtm(hunan, "lag GDPPC")
tmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)
```

### Spatial lag as a sum of neighbouring values 

We can calculate spatial lag as a sum of neighboring values by assigning binary weights. This requires us to go back to our neighbors list, then apply a function that will assign binary weights, then we use glist = in the nb2listw function to explicitly assign these weights.

We start by applying a function that will assign a value of 1 per each neighbor. This is done with lapply, which we have been using to manipulate the neighbors structure throughout the past notebooks. Basically it applies a function across each value in the neighbors structure.

```{r}
b_weights <- lapply(wm_q, function(x) 0*x + 1)
b_weights2 <- nb2listw(wm_q, 
                       glist = b_weights, 
                       style = "B")
b_weights2
```

With the proper weights assigned, we can use lag.listw to compute a lag variable from our weight and GDPPC.

```{r}
lag_sum <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))
lag.res <- as.data.frame(lag_sum)
colnames(lag.res) <- c("NAME_3", "lag_sum GDPPC")
```

Examine the result.

```{r}
lag_sum
```

Question: Can you understand the meaning of Spatial lag as a sum of neighboring values now? a simple summation of the neighbouring values without normalisation.

Next, we will append the *lag_sum GDPPC* field into `hunan` sf data frame by using the code chunk below.

```{r}
hunan <- left_join(hunan, lag.res)
```

Now, We can plot both the *GDPPC* and *Spatial Lag Sum GDPPC* for comparison using the code chunk below.

```{r}
gdppc <- qtm(hunan, "GDPPC")
lag_sum_gdppc <- qtm(hunan, "lag_sum GDPPC")
tmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)
```

### Spatial window average 

The spatial window average uses row-standardized weights and includes the diagonal element. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights.

To add the diagonal element to the neighbour list, we just need to use *include.self()* from **spdep**.

```{r}
wm_qs <- include.self(wm_q)
```

Notice that the Number of nonzero links, Percentage nonzero weights and Average number of links are 536, 6.921488 and 6.090909 respectively as compared to wm_q of 448, 5.785124 and 5.090909

Let us take a good look at the neighbour list of area \[1\] by using the code chunk below.

```{r}
wm_qs[[1]]
```

Notice that now \[1\] has six neighbours instead of five.

Now we obtain weights with *nb2listw()*

```{r}
wm_qs <- nb2listw(wm_qs)
wm_qs

```

Again, we use *nb2listw()* and *glist()* to explicitly assign weight values.

Lastly, we just need to create the lag variable from our weight structure and GDPPC variable.

```{r}
lag_w_avg_gpdpc <- lag.listw(wm_qs, 
                             hunan$GDPPC)
lag_w_avg_gpdpc
```

Next, we will convert the lag variable listw object into a data.frame by using *as.data.frame()*.

```{r}
lag.list.wm_qs <- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))
lag_wm_qs.res <- as.data.frame(lag.list.wm_qs)
colnames(lag_wm_qs.res) <- c("NAME_3", "lag_window_avg GDPPC")
```

Note: The third command line on the code chunk above renames the field names of *lag_wm_q1.res* object into *NAME_3* and *lag_window_avg GDPPC* respectively.

Next, the code chunk below will be used to append *lag_window_avg GDPPC* values onto *hunan* sf data.frame by using *left_join()* of **dplyr** package.

```{r}
hunan <- left_join(hunan, lag_wm_qs.res)
```

To compare the values of lag GDPPC and Spatial window average, `kable()` of Knitr package is used to prepare a table using the code chunk below.

```{r}
hunan %>%
  select("County", 
         "lag GDPPC", 
         "lag_window_avg GDPPC") %>%
  kable()
```

Lastly, *qtm()* of **tmap** package is used to plot the lag_gdppc and w_ave_gdppc maps next to each other for quick comparison.

```{r}
w_avg_gdppc <- qtm(hunan, "lag_window_avg GDPPC")
tmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)
```

### Spatial window sum

The spatial window sum is the counter part of the window average, but without using row-standardized weights.

To add the diagonal element to the neighbour list, we just need to use *include.self()* from **spdep**.

```{r}
wm_qs <- include.self(wm_q)
wm_qs
```

Next, we will assign binary weights to the neighbour structure that includes the diagonal element.

```{r}
b_weights <- lapply(wm_qs, function(x) 0*x + 1)
b_weights[1]
```

Notice that now \[1\] has six neighbours instead of five.

Again, we use *nb2listw()* and *glist()* to explicitly assign weight values.

```{r}
b_weights2 <- nb2listw(wm_qs, 
                       glist = b_weights, 
                       style = "B")
b_weights2
```

With our new weight structure, we can compute the lag variable with *lag.listw()*.

```{r}
w_sum_gdppc <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))
w_sum_gdppc
```

Next, we will convert the lag variable listw object into a data.frame by using *as.data.frame()*.

```{r}
w_sum_gdppc.res <- as.data.frame(w_sum_gdppc)
colnames(w_sum_gdppc.res) <- c("NAME_3", "w_sum GDPPC")
```

Note: The second command line on the code chunk above renames the field names of *w_sum_gdppc.res* object into *NAME_3* and *w_sum GDPPC* respectively.

Next, the code chunk below will be used to append *w_sum GDPPC* values onto *hunan* sf data.frame by using *left_join()* of **dplyr** package.

```{r}
hunan <- left_join(hunan, w_sum_gdppc.res)
```

To compare the values of lag GDPPC and Spatial window average, `kable()` of Knitr package is used to prepare a table using the code chunk below.

```{r}
hunan %>%
  select("County", "lag_sum GDPPC", "w_sum GDPPC") %>%
  kable()
```

Lastly, *qtm()* of **tmap** package is used to plot the lag_sum GDPPC and w_sum_gdppc maps next to each other for quick comparison.

```{r}
w_sum_gdppc <- qtm(hunan, "w_sum GDPPC")
tmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)
```
